 루트 파일시스템 만들기 

RYO (Roll Your Own)

임베디드 리눅스 초기에 루트 파일시스템을 만드는 유일한 방법

	l RYO 루트 파일시스템을 적용할 수 있는 경우
	- 램이나 저장소의 크기가 매우 제한적인 경우
	- 빠른 시연이 필요한 경우
	- 요구 사항이 표준 빌드 시스템 도구로 충족되지 않는 모든 경우

 루트 파일시스템에는 무엇이 있어야 하는가? 

커널은 부트로더로부터 포인터로 전달된 initramfs나 root= 파라미터를 통해 커널 명령줄에 지정된 블록 장치를 마운트함으로써 루트 파일 시스템을 구할 것

기본 설정으로 이름이 init인 첫 번째 프로그램을 실행할 것

init	모든 것을 시작시키는 프로그램
셸	명령 프롬프트를 보여주기 위해 필요
	init과 기타 프로그램이 호출하는 셸 스크립트를 실행하기 위해 필요
데몬	다른 프로그램에게 서비스를 제공하는 백그라운드 프로그램
	Init 프로그램은 주 시스템 애플리케이션들을 지원하기 위해 초기 데몬들을 시작해야 함
공유 라이브러리	대부분의 프로그램은 공유 라이브러리와 링크됨
	라이브러리는 루트 파일시스템에 있어야 함
구성 파일	Init과 기타 데몬용 구성 파일들은 일련의 텍스트 파일로, 보통 /etc 디렉터리에 저장
장치 노드	다양한 장치 드라이버에 접근할 수 있도록 해주는 특수 파일들
Proc과 sys	커널 자료구조를 디렉터리와 파일의 계층 구조로 나타내는 2개의 가상 파일시스템
여러 프로그램과 라이브러리 함수가 /proc과 /sys에 의존
커널 모듈 	커널의 일부를 모듈로 구성했다면, 루트 파일시스템 (/lib/modules/[커널 버전]) 에 설치돼야 함

<디렉터리 레이아웃>

리눅스 커널은 init=이나 rdinit= 을 통해 지정된 프로그램의 존재 외에는 파일과 디렉터리의 레이아웃에 신경 쓰지 않으므로 무엇이든 원하는대로 넣을 수 있음

리눅스 시스템의 기본 레이아웃은 FHS에 정의
FHS는 가장 큰 것부터 가장 작은 것까지 리눅스 운영체제의 구현을 모두 다룸

/bin	모든 사용자에게 필수적인 프로그램들
/dev	장치 노드와 기타 특수 파일들
/etc	시스템 구성
/lib	필수 공유 라이브러리
/proc	가상 파일로 표현되는 프로세스에 대한 정보
/sbin	시스템 관리자에게 필수적인 프로그램들
/sys	가상 파일로 표시되는 장치와 드라이버에 대한 정보
/tmp	임시 파일이나 휘발성 파일을 담아두는 곳
/user	/usr/bin, /usr/lib, /usr/sbin 디렉터리에는 각각 추가 프로그램, 라이브러리, 시스템 관리 유틸리티
/var	실행 중 변경될 수도 있는 파일과 디렉터리를 담고 있음

/bin과 /sbin 차이
	- /sbin은 비루트 사용자의 검색 경로에 포함될 필요가 없음
 
<스테이징 디렉터리>




<POSIX 파일 접근 권한>

사용자 ID(UID): 32비트 숫자로 표현
사용자 관련 정보: /etc/passwd에 저장
그룹 ID(GID): /etc/group에 저장

UID가 0인 루트 사용자와 GID가 0인 루트 그룹 존재
루트 사용자(슈퍼유저): 기본 구성에서 대부분의 권한 검사를 우회하고 시스템의 모든 자원에 접근할 수 있음
리눅스 기반 시스템에서의 보안은 주로 루트 계정에 접근하는 시도를 제한 하는 것과 관련

각 파일과 디렉터리도 소유자 존재, 하나의 그룹에 속함
프로세스의 파일/디렉터리 접근 수준은 파일의 모드라는 접근 권한 플래그의 집합에 의해 제어




SUID	프로그램 실행 시 프로세스의 effective UID가 파일 소유자의 UID로 바뀜
(Super User ID)
SGID	프로그램 실행 시 프로세스의 effective GID가 파일 소유자의 GID로 바뀜
(Special Group ID)
Sticky	디렉터리에서 삭제를 제한해 다른 사용자 소유의 파일을 지울 수 없도록 함
보통 /tmp와 /var/tmp 에 설정


<스테이징 디렉터리의 파일 소유권과 권한>

민감한 자원은 루트만 접근할 수 있도록 제한, 최소한의 프로그램을 비루트 사용자를 이용해 실행해야 함

다시 보기*************


<루트 파일시스템용 프로그램>
루트 파일시스템 작동에 필요한 필수 프로그램


	l init 프로그램
 실행되는 첫 번째 프로그램
	l 셸
스크립트를 실행하고 명령줄 프롬프트를 표시해서 사용자가 시스템과 상호작용하도록 하려면 셸이 필요
개발, 디버깅, 유지보수용으로는 유용

임베디드 시스템에서 많이 쓰이는 셸

Bash	유닉스 본 셸의 확대 집합으로 여러 확장과 고유 기능 존재
Ash	본 셸에 기반을 둔 셸, BusyBox는  bash와 더 호횐되도록 확장 된 버전의 ash를 가지고 있음
	Bash보다 훨씬 작음
Hush	매우 작은 셸, 메모리가 매우 작은 장치에 유용
BusyBox용 버전 존재

	l 유틸리티
기본적인 루트 파일시스템도 약 50가지 유틸리티 필요

BusyBox 등장 배경
	1. 각각의 소스 코드를 찾아 크로스 컴파일하는 어려움
	2. 컴파일된 프로그램들을 합치면 수십 메가에 이를 것인데 수 메가가 전부였던 초기 임베디드 리눅스에서는 문제
	
BusyBox 
필수 리눅스 유틸리티의 필수 기능을 수행하도록 처음부터 작성
80:20 규칙 활용
모든 도구를 하나의 바이너리로 묶어서 도구들 사이에 코드를 공유하기 쉽도록 하는 것



-> busybox 입력 시, 컴파일된 모든 애플릿 목록 확인 가능

BusyBox는 전형적으로 하나의 프로그램과 각 애플릿을 위한 심볼릭 링크로 설치되지만, 개별 애플리케이션의 묶음인 것처럼 동작
vi 편집기도 존재하여 텍스트 파일 수정 가능

<BusyBox 빌드하기>



Git 아카이브 복제




BusyBox를 스테이징 영역에 설치

<루트 파일시스템용 라이브러리>

프로그램은 라이브러리와 링크됨
둘 이상의 프로그램이 있는 경우 불필요하게 많은 양의 저장 공간을 차지, 툴체인으로부터 스테이징 디렉터리로 공유 라이브러리를 복사해야 함

	1. 툴체인의 sysroot 디렉터리에 있는 모든 .so 파일을 복사하기
	2. 필요한 라이브러리만 고르기





<스트립을 통한 크기 축소>

라이브러리와 프로그램은 종종 디버깅과 추적을 돕기 위해 심볼 테이블에 저장된 약간의 정보를 포함한 채로 컴파일됨
공간 절약을 하는 빠르고 간단한 방법은 바이너리에서 심볼테이블을 스트립 하는 것



커널 모듈 스트립
-> strip --strip-unneeded <모듈명>

<디바이스 노드>

디바이스 노드는 블록 장치나 문자 장치를 가리킴
블록 장치는 대용량 장치 (SD카드나 하드 드라이브)

	l 디바이스 노드 생성
	· 수동: mknod로 생성 가능
	· 자동: udev로 생성 가능

mknod <이름> <종류> <주번호> <부번호>

<이름> - 디바이스 노드의 이름
<종류> - 문자 장치 c, 블록 장치 b
<주번호>,<부번호> - 한쌍의 숫자, 커널이 파일 요청을 적절한 장치 드라이버 코드로 보낼 때 쓰임 
(Documentation/devices.txt 파일에 표준 주번호/부번호 목록 존재)

최소 루트 파일시스템에서 BusyBox로 부팅하기 위해서는 2개의 노드(console과 null)만 있으면 됨

console
노드 소유자인 루트만 접근할 수 있으면 됨 
접근 권한:  600 (rw------) 

null
모든 사람이 읽고 쓸 수 있어야 함
접근 권한: 666 (rw-rw-rw-)
 


<proc과 sysfs 파일시스템>

Proc과 sysfs 는 커널의 내부 동작을 보여주는 창과 같은 유사 파일시스템
둘다 커널 데이터를 디렉터리 계층 구조상의 파일들로 나타냄

Proc과 sysfs는 장치 드라이버 및 기타 커널 코드와 상호작용하는 또 다른 방법 제공

mount -t proc proc /proc
mount -t sysfs sysfs /sys

Proc
프로세스에 대한 정보를 사용자 공간에 노출하는 것
/proc/<PID>라는 디렉터리 존재
프로세스 목록 명령 ps-> 파일을 읽어 출력물을 만들어 냄
커널의 다른 부분에 대한 정보를 알려주는 파일 존재

/proc/sys
커널 서브시스템의 상태와 동작을 보여주고 제어하는 파일들 존재
man 5 proc-> 매뉴얼 페이지

Sysfs의 역할
커널 드라이버 모델을 사용자 공간에 제공하는 것
장치와 장치 드라이버에 관련된 파일의 계층 구조와 이들이 서로 연결된 방식에 대한 정보 제공

<파일시스템 마운트하기>
mount 명령-> 하나의 파일시스템을 다른 파일시스템 내의 디렉터리에 붙여서 파일시스템의 계층 구조를 만들 수 있음
커널이 부트될 때 맨 꼭대기에 마운트되는 파일시스템을 루트 파일시스템이라고 함 

mount [-t vfstype][-o 옵션]

Mount 명령은procfs와  nodevice 문자열을 무시

vfstype -> 파일시스템 종류
옵션 -> 콤마로 분리된 mount 옵션 목록
장치 ->  파일시스템이 존재하는 블록 장치 노드
디렉터리 -> 파일시스템을 마운트 하고자 하는 디렉터리


-o 뒤에 다양한 옵션을 지정할 수 있음

장치노드 /dev/proc은 없음-> why? 진짜가 아니라 유사 파일시스템이기 때문

<커널 모듈>

커널 모듈이 있다면 modules_install 커널 make 타깃을 이용해 루트 파일시스템에 설치해야 함
modprobe 명령에 필요한 구성 파일들과 함께 디렉터리 /lib/modules/<커널 버전>에 복사

<루트 파일시스템을 타깃으로 전송>

타깃으로의 전송
	1. initramfs
	부트로더에 의해 램에 로드되는 파일시스템 이미지
	램디스크는 만들기 쉽고 대용량 저장 장치 드라이버에 의존하지 않음
	주 루트 파일시스템을 업데이트 해야할 때 유지보수 모드로 사용할 수 있음
	작은 임베디드 장치에서 주 루트 파일시스템으로 사용 가능, 주류 리눅스 배포판에서 초기 사용자 공간으로 흔히 사용
	루트 파일시스템의 내용은 휘발성 (영구 저장 원할 시 또 다른 종류의 저장소가 필요)

	2. 디스크 이미지
	포맷되고 타깃의 대용량 저장 장치에 로드될 준비가 된 루트 파일시스템의 복사본
	
	3. 네트워크 파일시스템
	스테이징 디렉터리는 NFS 서버를 통해 네트워크로 export될 수 있고 타깃 부팅 때 마운트 될 수 있음
	
NFS를 이용해 네트워크를 통해 루트 파일시스템을 마운트 하는 방법

 부트 initranfs 만들기 

초기 램 파일시스템, 압축된 cpio 아카이브
cpio는 오래된 유닉스 아카이브 포맷
Initranfs를 지원하려면 커널을 COMFIG_BLK_DEV_INITRD로 구성해야함

부트 램디스크를 만드는 세가지 방법
	1. 단독형 cpio 아카이브 
	2. 커널 이미지에 내장된 cpio 아카이브
	3. 커널 빌드 시스템이 빌드의 일부로 처리하는 장치 테이블로 만드는 것

<단독형 initramfs>


	
	- owner root:root 옵션으로 실행한 이유는 파일 소유권 문제에 대한 간단한 해결책 (cpio아카이브 안에 있는 모든 파일들의 UID와 GID를 0으로 설정)
	
크기 문제 해결법
	1. 필요 없는 드라이버와 기능을 제거해서 커널 작게 만들기
	2. 필요 없는 유틸리티를 제고해서 BusyBox 작게 만들기
	3. glibc 대신 musl libc나 uclibc-ng 사용
	4. BusyBox를 정적으로 컴파일

<initramfs를 커널 이미지에 넣기>

리눅스는 initramfs를 커널 이미지에 넣도록 구성할 수 있음
-> 커널 구성을 바꾸고 CONFIG_INITRAMFS_SOURCE를 미리 만들어둔 cpio 아카이브의 전체 경로로 설정하면 됨

루트 파일시스템의 내용을 바꿀 때 마다 커널을 다시 빌드하고 .cpio 파일을 다시 만들어야 함

<장치 테이블을 이용해 initramfs 빌드하기>

장치 테이블
->  아카이브나 파일시스템 이미지에 저장되는 파일, 디렉터리, 장치 노드, 링크의 목록을 담고있는 텍스트파일
장점
-> 루트 특권 없이도 아카이브 파일 안에 루트 사용자나 다른 UID가 소유하는 항목들을 만들 수 있음
-> 루트 특권 없이 장치 트리 생성 가능

커널에는 initramfs를 만들 때 장치 테이블을 사용할 수 있는 기능이 있음
장치 테이블 파일을 작성한 다음 거기서 CONFIG_INITRAMFS_SOURCE를 가르킴
커널을 빌드하고 장치 테이블에 적힌 지시사항에 딸라 cpio 아카이브가 만들어짐

dir <name> <mode> <uid> <gid>
file <name> <location> <mode> <uid> <gid>
nod <name> <mod> <uid> <gid> <dev_type> <maj> <min>
slink <name> <target> <mode> <uid> <gid>


 init 프로그램 

Init은 구성 파일 /etc/init.d/rcS 를 읽으며 시작
Init 시작 했을 때

<데몬 프로세스 시작하기>

Syslogd
-> 다른 프로그램의 로그 메시지를 기록
Respawn
-> 프로그램이 종료되면, 자동으로 다시 실행
-n
-> 포그라운드 프로세스로 실행해야 함

로그는 /var/log/messages에 기록

 사용자 계정 구성하기 

특권이 없는 사용자 계정을 만들고 루트 권한 전부가 필요치 않은 경우에 사용하는 것이 좋음
사용자 이름은 /etc/passwd 에 설정
한 줄이 하나의 사용자를 나타내며 콜론으로 구분된 7개의 필드가 존재

	- 로그인 이름
	- 패스워드를 검증하기 위한 해시코드 (보통은 민감한 정보의 노출을 줄이기 위해 패스워드가 /etc/shadow에 저장돼 있음을 나타내는 x가 들어있음)
	- 코멘트 필드, 종종 빈칸으로 남겨둠
	- 사용자의 홈 디렉터리
	- 사용자가 사용할 셸

그룹 이름은 /etc/groups에 비슷한 방식으로 저장
한 줄이 하나의 그룹을 나타내며 콜론으로 구분된 4개의 필드가 존재 
	- 그룹 이름
	- 그룹 패스워드, 일반적으로는 그룹 패ㅐ스워드가 없음을 나타내는 x 문자
	- GID, 즉 그룹 ID
	- 선택 사항으로, 그룹에 속하는 사용자의 목록. 콤마로 구분

<루트 파일시스템에 사용자 계정 추가하기>

스테이징 디렉터리에 etc/passwd, etc/shadow, et/group 파일을 추가해야 함 

Shadow 파일의 권한은 0600이어야함
그 다음, getty라는 프로그램을 기동해서 로그인 절차를 시작해야함
Busybox에는 getty가 있음 
Getty는 로그인 셸이 종료될 때 inittab에서 respawn 키워드를 통해 실행됨

<장치 노드를 관리하는 더 좋은 방법>

장치 노드 만드는 방법

	- devtmpfs: 
	부트 때 /dev에 마운트 할 수 있는 의사 파일시스템. 새로운 장치들에 대한 노드를 만들음
	노드의 소유자는 루트, 기본 권한은 0666
	Devtmpfs 파일시스템 지원은 커널 구성 변수 CONFIG_DEVTMPFS에 의해 제어
	커널 구성에서 CONFIG_DEVTMPFS_MOUNT를 활성화하면 커널은 루트 파일시스템을 마운트한 직후 자동으로 devtmpfs를 마운트
			
	- mdev: 
	디렉터리를 장치 노드로 채우고 필요에 따라 새로운 노드를 만드는 데 쓰이는 Busybox 애플릿   
	구성 파일인 /etc/mdev.conf는 노드의 소유권과 권한에 대한 규칙을 담고 있음
	만들어지는 장치 노드의 권한을 수정할 수 있도록 해줌
	-s 옵션으로 mdev를 실행하면, mdev가 /sys 디렉터리를 스캔해서 현재 장치에 대한 정보를 찾고 /dev 디렉터리를 해당 노드로 채움
	추가되는 새로운 장치들을 계속해서 추적해서 필요한 노드들을 만들어주고 싶다면, /proc/sys/kernel/hotplug에 씀으로써 mdev에게 핫플러그 클라이언트를 만들어줘야함
	다음 명령을 /etc/init.d/rcSdp 추가하면 됨
	

	
	기본 모드는 660, 소유권은 root::root (변경 원할 시, /etc/mdev.conf에 규칙 추가)
	
	- Udev:
	주류 리눅스에서 mdev에서 해당하는 기능이며, 현재 systemd의 일부
	데스크톱 리눅스와 일부 임베디드에서 찾아볼 수 있음
	

 네트워크 구성하기  
	
주 네트워크 구성은 /etc/network/interfaces에 저장

<glibc용 네트워크 요소>

Glibc는 NSS(Name Service Switch)라는 매커니즘을 사용해서 이름을 네트워크나 사용자 관련 숫자로 변환하는 방식을 제어
/etc/nsswitch.conf 로 설정됨

호스트 이름을 제외하면, 모두 /etc/ 안에 있는 해당 이름의 파일을 통해 변환됨
호스트 이름은 /etc/hosts 에 없다면 추가적으로 DNS 검색을 통해 변환
/etc/에 이들 파일을 넣으면 작동함. 
네트워크, 프로토콜, 서비스는 모든 리눅스 시스템에서 동일하므로 개발 PC의 /etc로부터 복사해도됨
/etc/hosts는 최소한 루프백 주소를 담고있어야 함





 장치 테이블을 이용해 파일시스템 이미지 만들기 

ext2는 SD 카드를 포함하는 관리형 프래시 메모리에 쓰임

genext2fs 도구를 설치해야 함

Genext2fs는 <name> <type> <mode> <uid> <gid> <major> <minor> <start> <inc> <count>형식의 장치 테이블 파일을 사용

Name: 파일명
Type:( f ) 보통 파일
	( d ) 디렉터리
	( c ) 문자 특수 장치 파일
	( b ) 블록 특수 장치 파일
	( p ) FIFO
uid: 파일의 uid
gid: 파일의 gid
Major와 minor: 장치 번호
start, inc, count: minor 번호가 start에서 시작하는 장치 노드 그룹을 만들 수 있도록 함

Genext2fs를 이용해 4MiB 의 파일시스템 이미지를 만들음
결과로 만들어진 이미지를 SD 카드 등에 복사 가능

<NFS를 이용해 루트 파일시스템 마운트하기>

장치에 네트워크 인터페이스가 있으면 개발 중에는 네트워크를 통해 루트 파일시스템을 마운트하는 것이 가장 좋음

호스트에 NFS 서버를 설치하고 구성해야 함
NFS 서버는 /etc/exports로 제어됨, 각줄은 하나의 export를 나타냄

*는 로컬 네트워크의 모든 주소에 대해 디렉터리를 export
원한다면, 여기에 하나의 IP 주소나 범위를 지정할 수 있음
*와 여는 괄호 사이에는 빈칸이 없어야 함


rw: 디렉터리를 읽고 쓰기로 export 
sync: 동기 버전 NFS 프로토콜을 선택한다. 동기버전은 비동기 버전보다 더 견고하지만 약간 느림
no_subtree_check: 서브 트리 확인을 비활성화, 보안에 영향이 있지만 경우에 따라 신뢰성이 높아짐
no_root_squash: 사용자 ID 0으로 전달된 요청을 다른 사용자 ID로 바꾸지 않고 처리하도록 허용

/etc/exports를 수정했으면 NFS 서버를 재기동해 수정 사항이 반영되도록 함
타깃이 NFS를 통해 루트 파일시스템을 마운트하도록 설정해야 함 
이를 위해서는 커널이 CONFIG_ROOT_NFS 로 구성돼있어야 함

Root=/dev/nfs rw  nfsroot=<호스트-ip>:<루트-디렉터리> ip=<타깃-ip>

보기 옵션
rw: 루트 파일시스템을 읽고 쓰기로 마운트
Nfsroot: 호스트의 ip 주소, export된 루트 파일시스템의 경로를 지정
Ip: 타깃에 할당된 IP 주소, 실행 때 할당됨, 이 경우 루트 파일시스템이 마운트되고 init이 시작하기 전에 인터페이스가 구성돼야 함, 커널 명령줄에 구성


<파일 권한 문제> 

커널 소스 코드나 DTB를 수정할 때 NFS가 제공하는 빠른 속도와 동일한 이점을 얻는 방법
-> TFTP


 TFTP를 이용해 커널 로드하기 

TFTP 는 매우 간단한 파일 전송 프로토콜, U-Boot 같은 부트로더에서 구현하기 쉽도록 설계
호스트에 TFTP 데몬을 설치해야 함



Ttftpd-hpa 는 디폴트로 /var/lib/tftpboot 디렉터리에 있는 파일들에 대한 읽기 전용 접근을 허용
Tftpd-hpa가 설치되고 실행되면, 타깃으로 복사하고 싶은 파일을 /var/lib/tftpboot 디렉터리로 복사
u-boot 명령 프롬프트에 다음 명령 입력


Tftpboot 도중 끊임없이 글자 T를 출력하여 진행이 안되는 경우 존재 (이는 TFTP 요청 시간 제한을 초과했다는 뜻)
이런 일이 일어나는 이유
	- 서버의 IP 주소가 잘못됨
	- 서버에서 TFTP 데몬이 동작하지 않고 있음
	- 서버의 방화벽이 TFTP 프로토콜을 막고 있음, 대부분의 방화벽은 디폴트 설정에서 실제로 TFTP포트 69번을 막음

![Uploading image.png…]()
